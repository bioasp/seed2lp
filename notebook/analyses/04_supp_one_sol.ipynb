{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get computing time data to obtain the first solution\n",
    "This notebook presents computing time data to get the first solution with Seed2Lp, with a timeout at 45 min, in full Network or Target mode, without accumulation allowed, only for subset minimal optimization.\n",
    "\n",
    "\n",
    "To run correctly this notebook and have the same results as the paper, you must first download the raw results: [https://doi.org/10.57745/OS1JND](https://doi.org/10.57745/OS1JND)\n",
    "\n",
    "This notebook is written with the hierarchy of downloaded files, if you want to try it with the test form the run notebooks, it is needed to first restructure your data to match the hierarchy of downloaded files.\n",
    "\n",
    "We suppose here that the downloaded files are in a directory named \"analyses\", this directory path can be changed to your directory path where the data are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- Download and Install *R*: https://cran.r-project.org/\n",
    "- Type `R` in your console, the R lanuage will run.\n",
    "- Execute the command: `install.packages('IRkernel', repos = 'http://cran.us.r-project.org');IRkernel::installspec()`\n",
    "- Execute the command: `install.packages(\"reshape2\")`\n",
    "- Execute the command: `install.packages(\"data.table\")`\n",
    "- Execute the command: `install.packages(\"ggplot2\")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the package rpv2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rpy2\n",
      "  Using cached rpy2-3.5.16.tar.gz (220 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.15.1 in /home/cghassem/miniconda3/envs/s2lp/lib/python3.11/site-packages (from rpy2) (1.16.0)\n",
      "Requirement already satisfied: jinja2 in /home/cghassem/miniconda3/envs/s2lp/lib/python3.11/site-packages (from rpy2) (3.1.4)\n",
      "Collecting tzlocal (from rpy2)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pycparser in /home/cghassem/miniconda3/envs/s2lp/lib/python3.11/site-packages (from cffi>=1.15.1->rpy2) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/cghassem/miniconda3/envs/s2lp/lib/python3.11/site-packages (from jinja2->rpy2) (2.1.5)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: rpy2\n",
      "  Building wheel for rpy2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rpy2: filename=rpy2-3.5.16-cp311-cp311-linux_x86_64.whl size=261792 sha256=88a2022583d7fb3ab79ea21354bf08cc3e5e137e1ebc0e57556ab42091e4874e\n",
      "  Stored in directory: /home/cghassem/.cache/pip/wheels/da/60/76/3bc67cbf19cb7dd4806c73262e7588dfada92f80fcf3558fc5\n",
      "Successfully built rpy2\n",
      "Installing collected packages: tzlocal, rpy2\n",
      "Successfully installed rpy2-3.5.16 tzlocal-5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rpy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to change (if wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_dir = \"../../analyses\"\n",
    "data_dir = f\"{analyse_dir}/data\"\n",
    "\n",
    "# Directories to create for R analyses and plots\n",
    "timer_tables_dir = f\"{analyse_dir}/results/timer_one_sol/tables\"\n",
    "timers_plot_dir = f\"{analyse_dir}/results/timer_one_sol/plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(timer_tables_dir):\n",
    "    os.makedirs(timer_tables_dir)\n",
    "\n",
    "if not os.path.isdir(timers_plot_dir):\n",
    "    os.makedirs(timers_plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = os.path.join(analyse_dir, \"results\")\n",
    "one_sol_results_dir = os.path.join(result_dir, \"one_solution\")\n",
    "one_sol_supp_data = os.path.join(result_dir,\"supp_data\",\"one_solution_supp_data.tsv\")\n",
    "sbml_dir = f'{data_dir}/bigg/sbml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timers(file_path, mode):\n",
    "    table_all = pd.read_csv(file_path, sep='\\t', lineterminator='\\n')\n",
    "    table_all=table_all.fillna(-50)\n",
    "    table_all.loc[table_all[\"minimize\"] == \"unsat\", \"minimize\"] = -100\n",
    "    table_all.loc[table_all[\"minimize_opti\"] == \"unsat\", \"minimize_opti\"] = -100\n",
    "    table_all.loc[table_all[\"submin\"] == \"unsat\", \"submin\"] = -100\n",
    "    table_all.loc[table_all[\"minimize\"] == \"Time out\", \"minimize\"] = -200\n",
    "    table_all.loc[table_all[\"minimize\"] == \"time out\", \"minimize\"] = -200\n",
    "    table_all.loc[table_all[\"minimize_opti\"] == \"Time out\", \"minimize_opti\"] = -200\n",
    "    table_all.loc[table_all[\"minimize_opti\"] == \"time out\", \"minimize_opti\"] = -200\n",
    "    table_all.loc[table_all[\"submin\"] == \"Time out\", \"submin\"] = -200\n",
    "    table_all.loc[table_all[\"submin\"] == \"time out\", \"submin\"] = -200\n",
    "    table_all['minimize'] = table_all['minimize'].astype('float')\n",
    "    table_all['minimize_opti'] = table_all['minimize_opti'].astype('float')\n",
    "    table_all['submin'] = table_all['submin'].astype('float')\n",
    "\n",
    "    timers_all= table_all.loc[table_all[\"type_data\"] == \"Solving (sec)\"]\n",
    "    # No accumulation mode\n",
    "    timers_all = timers_all[timers_all['accumulation']==False]\n",
    "\n",
    "    if mode == \"full\":\n",
    "        return timers_all[timers_all[\"search_mode\"]==\"Full network\"]\n",
    "    elif mode == \"target\":\n",
    "        return timers_all[timers_all[\"search_mode\"]==\"Target\"]\n",
    "    else:\n",
    "        return timers_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fluxes(directory:str, mode:str, optim:str=None):\n",
    "    flux_all=pd.DataFrame(columns=['species', 'biomass_reaction', 'solver_type', 'search_mode',\n",
    "                                     'search_type', 'accumulation', 'model', 'size', 'lp_flux', 'cobra_flux_init',\n",
    "                                     'cobra_flux_no_import', 'cobra_flux_seeds', 'cobra_flux_demands',\n",
    "                                     'has_flux', 'has_flux_seeds', 'has_flux_demands', 'timer'])\n",
    "    flux_all['accumulation'] = flux_all['accumulation'].astype('bool')\n",
    "    flux_all['has_flux'] = flux_all['has_flux'].astype('bool')\n",
    "    flux_all['has_flux_seeds'] = flux_all['has_flux_seeds'].astype('bool')\n",
    "    flux_all['has_flux_demands'] = flux_all['has_flux_demands'].astype('bool')\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(directory):\n",
    "        for filename in [f for f in filenames if (f.endswith(\"_fluxes.tsv\") or f.endswith(\"_fluxes_from_result.tsv\"))]:\n",
    "            # By default in this notebook we want the no accumulation mode for seed2lp results\n",
    "            if  \"_no_accu_\" in filename \\\n",
    "                and   ((mode == \"full\" and \"_fn_\" in filename) \\\n",
    "                    or (mode == \"target\" and \"_tgt_\" in filename))\\\n",
    "                or mode == \"netseed\":\n",
    "                file_path=os.path.join(dirpath, filename)\n",
    "                current_df = pd.read_csv(file_path, sep='\\t', lineterminator='\\n')\n",
    "                current_df['accumulation'] = current_df['accumulation'].astype('bool')\n",
    "                current_df['has_flux'] = current_df['has_flux'].astype('bool')\n",
    "                current_df['has_flux_seeds'] = current_df['has_flux_seeds'].astype('bool')\n",
    "                current_df['has_flux_demands'] = current_df['has_flux_demands'].astype('bool')\n",
    "                flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
    "    flux_all = flux_all[flux_all[\"model\"]!=\"model_one_solution\"]\n",
    "    flux_all = flux_all[flux_all[\"model\"]!=\"model_one_solution\"]\n",
    "    if optim==\"submin\":\n",
    "        return flux_all[flux_all[\"search_mode\"]==\"Subset Minimal\"]\n",
    "    elif optim==\"min\":\n",
    "        return flux_all[flux_all[\"search_mode\"]==\"Minimize\"]\n",
    "    else:\n",
    "        return flux_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timers_table(table:pd.DataFrame, optim, list_all_species, dict_species):\n",
    "    column_conversion = {\"REASONING\":\"Reasoning\",\n",
    "                         \"REASONING FILTER\":\"Filter\",\n",
    "                         \"REASONING GUESS-CHECK\":'Guess-Check',\n",
    "                         \"REASONING GUESS-CHECK-DIVERSITY\":'Guess-Check-div'}\n",
    "\n",
    "    \n",
    "    set_complete = set(list_all_species)\n",
    "    set_reasoning = set(dict_species[\"reasoning\"])\n",
    "    set_filter = set(dict_species[\"filter\"])\n",
    "    set_gc = set(dict_species[\"gc\"])\n",
    "    set_gcd = set(dict_species[\"gcd\"])\n",
    "    \n",
    "    diff_reasoning = set_complete.difference(set_reasoning) \n",
    "    diff_filter = set_complete.difference(set_filter) \n",
    "    diff_gc = set_complete.difference(set_gc) \n",
    "    diff_gcd = set_complete.difference(set_gcd) \n",
    "    new_table=pd.DataFrame(columns=['network', 'Reasoning','Filter',\n",
    "                                'Guess-Check', 'Guess-Check-div'])\n",
    "    new_table = new_table.set_index('network')\n",
    "\n",
    "    for row in table.iterrows():\n",
    "        network = row[0]\n",
    "        if not new_table.empty:\n",
    "            if network in new_table.index:\n",
    "                new_table.loc[network, column_conversion[row[1]['mode']]]=row[1][optim]\n",
    "            else:\n",
    "                new_table = add_row(new_table, row, optim, column_conversion)\n",
    "        else:\n",
    "            new_table = add_row(new_table, row, optim, column_conversion)\n",
    "\n",
    "    for net in diff_reasoning:\n",
    "        new_table.loc[net, [\"Reasoning\"]]=-1000\n",
    "    for net in diff_filter:\n",
    "        new_table.loc[net, [\"Filter\"]]=-1000\n",
    "    for net in diff_gc:\n",
    "        new_table.loc[net, [\"Guess-Check\"]]=-1000\n",
    "    for net in diff_gcd:\n",
    "        new_table.loc[net, [\"Guess-Check-div\"]]=-1000\n",
    "    return new_table.reset_index()\n",
    "\n",
    "\n",
    "def add_row(new_table,row, optim, column_conversion):\n",
    "    network = row[1]['network']\n",
    "    current = pd.DataFrame(data=[[network, row[1][optim]]], columns=['network', column_conversion[row[1]['mode']]])\n",
    "    current = current.set_index('network')\n",
    "    new_table = new_table.combine_first(current)\n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_separate_data(table):\n",
    "    table[\"solver_type\"] = table[\"solver_type\"].str.replace('REASONING  GUESS-CHECK-DIVERSITY', 'REASONING GUESS-CHECK DIVERSITY')\n",
    "    table[\"solver_type\"] = table[\"solver_type\"].str.replace('REASONING  GUESS-CHECK', 'REASONING GUESS-CHECK')\n",
    "    table[\"solver_type\"] = table[\"solver_type\"].str.replace('REASONING  FILTER', 'REASONING FILTER')\n",
    "    \n",
    "    # CLASSIC\n",
    "    table_reasoning = table[table[\"solver_type\"]==\"REASONING\"]\n",
    "    \n",
    "    # FILTER\n",
    "    table_filter = table[table[\"solver_type\"]==\"REASONING FILTER\"]\n",
    "\n",
    "    # GUESS_CHECK\n",
    "    table_gc = table[table[\"solver_type\"]==\"REASONING GUESS-CHECK\"]\n",
    "\n",
    "    # GUESS_CHECK_DIV\n",
    "    table_gcd = table[table[\"solver_type\"]==\"REASONING GUESS-CHECK DIVERSITY\"]\n",
    "\n",
    "    return table_reasoning, table_filter, table_gc, table_gcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_plot(table,column_name):\n",
    "    new_table = table.groupby(['species'])[column_name].agg('count').reset_index()\n",
    "    new_table=new_table.rename(columns={column_name: \"Total_flux\"})\n",
    "    new_true = table[table[column_name]==True].groupby(['species'])[column_name].agg('count').reset_index()\n",
    "    new_true=new_true.rename(columns={column_name: \"True_flux\"})\n",
    "    new_false = table[table[column_name]==False].groupby(['species'])[column_name].agg('count').reset_index()\n",
    "    new_false=new_false.rename(columns={column_name: \"False_flux\"})\n",
    "    new_table=pd.merge(new_table,new_true, how='left', on=['species'])\n",
    "    new_table=pd.merge(new_table,new_false, how='left', on=['species'])\n",
    "    new_table=new_table.fillna(0)\n",
    "    new_table=new_table.fillna(0)\n",
    "    new_table['True_flux']=new_table['True_flux'].astype(int)\n",
    "    new_table['False_flux']=new_table['False_flux'].astype(int)\n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_species(table):\n",
    "    labels = table['species'].tolist()\n",
    "    set_labels = set(labels)\n",
    "    return set_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_species():\n",
    "    species_files = os.listdir(sbml_dir)\n",
    "    species = [sub.replace('.xml', '') for sub in species_files]\n",
    "    return species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "timers_FN=get_timers(one_sol_supp_data, \"full\")\n",
    "timers_T=get_timers(one_sol_supp_data, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n",
      "/tmp/ipykernel_11027/2993539488.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  flux_all=pd.concat([flux_all if not flux_all.empty else None, current_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "flux_FN = get_fluxes(one_sol_results_dir, \"full\", \"submin\")\n",
    "flux_T = get_fluxes(one_sol_results_dir, \"target\", \"submin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_reasoning, FN_filter, FN_gc, FN_gcd = get_separate_data(flux_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_reasoning, T_filter, T_gc, T_gcd = get_separate_data(flux_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_reasoning_tab=create_table_plot(FN_reasoning,'has_flux')\n",
    "FN_filter_tab=create_table_plot(FN_filter,'has_flux')\n",
    "FN_gc_tab=create_table_plot(FN_gc,'has_flux')\n",
    "FN_gcd_tab=create_table_plot(FN_gcd,'has_flux')\n",
    "\n",
    "T_reasoning_tab=create_table_plot(T_reasoning,'has_flux')\n",
    "T_filter_tab=create_table_plot(T_filter,'has_flux')\n",
    "T_gc_tab=create_table_plot(T_gc,'has_flux')\n",
    "T_gcd_tab=create_table_plot(T_gcd,'has_flux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_species_FN = {\"reasoning\": get_list_species(FN_reasoning_tab),\n",
    "                    \"filter\":get_list_species(FN_filter_tab),\n",
    "                    \"gc\":get_list_species(FN_gc_tab),\n",
    "                    \"gcd\":get_list_species(FN_gcd_tab)}\n",
    "\n",
    "dict_species_T = {\"reasoning\":get_list_species(T_reasoning_tab),\n",
    "                    \"filter\":get_list_species(T_filter_tab),\n",
    "                    \"gc\":get_list_species(T_gc_tab),\n",
    "                    \"gcd\":get_list_species(T_gcd_tab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all_species = get_all_species()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "timers_FN_final = convert_timers_table(timers_FN, \"submin\",  list_all_species, dict_species_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "timers_T_final = convert_timers_table(timers_T, \"submin\",  list_all_species, dict_species_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot uses R to get the data tables from `timer_tables_dir` variable, so we are saving data (set at the begining of the notebook in paragraphe  [Variable to change](#variable-to-change-if-wanted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "timers_FN_final.to_csv(f\"{timer_tables_dir}/Full_Network.tsv\", sep='\\t')\n",
    "timers_T_final.to_csv(f\"{timer_tables_dir}/Target.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part uses R to get the data tables from `timer_tables_dir` variable and write it in `timers_plot_dir` directory (set at the begining of the notebook in paragraphe  [Variable to change](#variable-to-change-if-wanted) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
      "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
      "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
      "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
      "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
      "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
      "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n",
      "`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data.table 1.16.0 using 4 threads (see ?getDTthreads).  Latest news: r-datatable.com\n",
       "\n",
       "Attachement du package : data.table\n",
       "\n",
       "Les objets suivants sont masqus depuis package:reshape2:\n",
       "\n",
       "    dcast, melt\n",
       "\n",
       "Using network as id variables\n",
       "Using network as id variables\n",
       "De plus : Messages d'avis :\n",
       "1: Dans (function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE,  :\n",
       "  les bibliothques /usr/local/lib/R/site-library, /usr/lib/R/site-library ne contiennent aucun package\n",
       "2: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\n",
       " Please use `after_stat(count)` instead.\n",
       "This warning is displayed once every 8 hours.\n",
       "Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n",
       "generated. \n",
       "3: Removed 3 rows containing non-finite outside the scale range (`stat_bin()`). \n",
       "4: Removed 4 rows containing non-finite outside the scale range (`stat_bin()`). \n",
       "5: Removed 4 rows containing non-finite outside the scale range (`stat_bin()`). \n",
       "6: Removed 1 row containing non-finite outside the scale range (`stat_bin()`). \n",
       "7: Removed 36 rows containing non-finite outside the scale range (`stat_bin()`). \n",
       "8: Removed 17 rows containing non-finite outside the scale range (`stat_bin()`). \n",
       "9: Removed 8 rows containing non-finite outside the scale range (`stat_bin()`). \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i timer_tables_dir -i timers_plot_dir\n",
    "library(reshape2)\n",
    "library(data.table)\n",
    "library(ggplot2)\n",
    "\n",
    "\n",
    "# create output directory if it does not exist\n",
    "if (!dir.exists(timers_plot_dir)) {\n",
    "    dir.create(timers_plot_dir)\n",
    "}\n",
    "\n",
    "# read all files in the input directory\n",
    "files <- list.files(timer_tables_dir, full.names = TRUE)\n",
    "\n",
    "# loop over all files\n",
    "for (file in files) {\n",
    "    # read the data\n",
    "    data <- read.table(file, header = TRUE) # , row.names = 1\n",
    "    # get the name of the file, no extension\n",
    "    file_id <- sub(pattern = \"(.*)\\\\..*$\", replacement = \"\\\\1\", basename(file))\n",
    "    \n",
    "    # replace -200 with 2700\n",
    "    data[data == -200] <- 2700\n",
    "\n",
    "    # replace -100 with NA\n",
    "    data[data == -1000] <- NA\n",
    "\n",
    "    # get long data from wide format, id = row names\n",
    "    data_long <- reshape2::melt(data, variable.name = \"Group\", value.name = \"Time\")\n",
    "\n",
    "\n",
    "    # plot the data\n",
    "    p = ggplot(data_long, aes(x = Time, color = Group)) +\n",
    "        stat_bin(data = subset(data_long, Group == \"Filter\"), aes(y = cumsum(..count..)), geom = \"step\") +\n",
    "        stat_bin(data = subset(data_long, Group == \"Guess.Check\"), aes(y = cumsum(..count..)), geom = \"step\") +\n",
    "        stat_bin(data = subset(data_long, Group == \"Guess.Check.div\"), aes(y = cumsum(..count..)), geom = \"step\") +\n",
    "        stat_bin(data = subset(data_long, Group == \"Reasoning\"), aes(y = cumsum(..count..)), geom = \"step\") +\n",
    "        # style the plot\n",
    "        theme_bw() +\n",
    "        labs(title = file_id, x = \"Time\", y = \"Cumulative count of GSMNs with solutions\", colour = \"Solving mode\") +\n",
    "        # scale_color_manual(values = c(\"Filter\" = \"red\", \"Guess.Check\" = \"blue\", \"Guess.Check.div\" = \"green\", \"Reasoning\" = \"black\")) +\n",
    "        # increase font size\n",
    "        theme(text = element_text(size = 15))\n",
    "\n",
    "    # save the plot\n",
    "    ggsave(paste0(timers_plot_dir, \"/\", file_id, \".pdf\"), plot = p, width = 10, height = 7)\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
